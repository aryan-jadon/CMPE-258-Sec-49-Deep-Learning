{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Catchup-Assignment-2-PartA-Graph Classification-Problem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Networks"
      ],
      "metadata": {
        "id": "H6zJE6dkGV0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "xTMmdoH_0CYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"/content/data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"/content//saved_models/\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4h5tXjJg7VF",
        "outputId": "9dba0378-d2fe-4772-979f-fdff835ec1ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Dataset and Weights"
      ],
      "metadata": {
        "id": "vqPjrnwMxhri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "# Github URL where saved models are stored for this tutorial\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
        "\n",
        "# Files to download\n",
        "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
        "\n",
        "# Create checkpoint path if it doesn't exist yet\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "# For each file, check whether it already exists. If not, try downloading it.\n",
        "for file_name in pretrained_files:\n",
        "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
        "    if \"/\" in file_name:\n",
        "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
        "    if not os.path.isfile(file_path):\n",
        "        file_url = base_url + file_name\n",
        "        print(f\"Downloading {file_url}...\")\n",
        "        try:\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "        except HTTPError as e:\n",
        "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
      ],
      "metadata": {
        "id": "ScMXrTGnGW3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cca2e9-0ad3-42ce-d6e9-3e5b90614947"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers Presentation"
      ],
      "metadata": {
        "id": "2xgKI98Exkae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GCN Layer"
      ],
      "metadata": {
        "id": "FgIFHJmb0O8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Linear(c_in, c_out)\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            node_feats - Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
        "            adj_matrix - Batch of adjacency matrices of the graph. If there is an edge from i to j, adj_matrix[b,i,j]=1 else 0.\n",
        "                         Supports directed edges by non-symmetric matrices. Assumes to already have added the identity connections.\n",
        "                         Shape: [batch_size, num_nodes, num_nodes]\n",
        "        \"\"\"\n",
        "        # Num neighbours = number of incoming edges\n",
        "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
        "        node_feats = self.projection(node_feats)\n",
        "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
        "        node_feats = node_feats / num_neighbours\n",
        "        return node_feats\n",
        "\n",
        "\n",
        "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
        "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
        "                            [1, 1, 1, 1],\n",
        "                            [0, 1, 1, 1],\n",
        "                            [0, 1, 1, 1]]])\n",
        "\n",
        "print(\"Node features:\\n\", node_feats)\n",
        "print(\"\\nAdjacency matrix:\\n\", adj_matrix)\n",
        "\n",
        "layer = GCNLayer(c_in=2, c_out=2)\n",
        "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
        "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
        "\n",
        "with torch.no_grad():\n",
        "    out_feats = layer(node_feats, adj_matrix)\n",
        "\n",
        "print(\"Adjacency matrix\", adj_matrix)\n",
        "print(\"Input features\", node_feats)\n",
        "print(\"Output features\", out_feats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8FPRcTZxX5S",
        "outputId": "ec750c1f-d492-49a7-e693-7f3673a08d03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features:\n",
            " tensor([[[0., 1.],\n",
            "         [2., 3.],\n",
            "         [4., 5.],\n",
            "         [6., 7.]]])\n",
            "\n",
            "Adjacency matrix:\n",
            " tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.]]])\n",
            "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.]]])\n",
            "Input features tensor([[[0., 1.],\n",
            "         [2., 3.],\n",
            "         [4., 5.],\n",
            "         [6., 7.]]])\n",
            "Output features tensor([[[1., 2.],\n",
            "         [3., 4.],\n",
            "         [4., 5.],\n",
            "         [4., 5.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GAT Layer"
      ],
      "metadata": {
        "id": "4l0pA-XGx1rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GATLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimensionality of input features\n",
        "            c_out - Dimensionality of output features\n",
        "            num_heads - Number of heads, i.e. attention mechanisms to apply in parallel. The\n",
        "                        output features are equally split up over the heads if concat_heads=True.\n",
        "            concat_heads - If True, the output of the different heads is concatenated instead of averaged.\n",
        "            alpha - Negative slope of the LeakyReLU activation.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.concat_heads = concat_heads\n",
        "        if self.concat_heads:\n",
        "            assert c_out % num_heads == 0, \"Number of output features must be a multiple of the count of heads.\"\n",
        "            c_out = c_out // num_heads\n",
        "\n",
        "        # Sub-modules and parameters needed in the layer\n",
        "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
        "        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * c_out)) # One per head\n",
        "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
        "\n",
        "        # Initialization from the original implementation\n",
        "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            node_feats - Input features of the node. Shape: [batch_size, c_in]\n",
        "            adj_matrix - Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]\n",
        "            print_attn_probs - If True, the attention weights are printed during the forward pass (for debugging purposes)\n",
        "        \"\"\"\n",
        "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n",
        "\n",
        "        # Apply linear layer and sort nodes by head\n",
        "        node_feats = self.projection(node_feats)\n",
        "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
        "\n",
        "        # We need to calculate the attention logits for every edge in the adjacency matrix\n",
        "        # Doing this on all possible combinations of nodes is very expensive\n",
        "        # => Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges\n",
        "        edges = adj_matrix.nonzero(as_tuple=False) # Returns indices where the adjacency matrix is not 0 => edges\n",
        "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
        "        edge_indices_row = edges[:,0] * num_nodes + edges[:,1]\n",
        "        edge_indices_col = edges[:,0] * num_nodes + edges[:,2]\n",
        "        a_input = torch.cat([\n",
        "            torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
        "            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)\n",
        "        ], dim=-1) # Index select returns a tensor with node_feats_flat being indexed at the desired positions along dim=0\n",
        "\n",
        "        # Calculate attention MLP output (independent for each head)\n",
        "        attn_logits = torch.einsum('bhc,hc->bh', a_input, self.a)\n",
        "        attn_logits = self.leakyrelu(attn_logits)\n",
        "\n",
        "        # Map list of attention values back into a matrix\n",
        "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape+(self.num_heads,)).fill_(-9e15)\n",
        "        attn_matrix[adj_matrix[...,None].repeat(1,1,1,self.num_heads) == 1] = attn_logits.reshape(-1)\n",
        "\n",
        "        # Weighted average of attention\n",
        "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
        "        if print_attn_probs:\n",
        "            print(\"Attention probs\\n\", attn_probs.permute(0, 3, 1, 2))\n",
        "        node_feats = torch.einsum('bijh,bjhc->bihc', attn_probs, node_feats)\n",
        "\n",
        "        # If heads should be concatenated, we can do this by reshaping. Otherwise, take mean\n",
        "        if self.concat_heads:\n",
        "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
        "        else:\n",
        "            node_feats = node_feats.mean(dim=2)\n",
        "\n",
        "        return node_feats\n",
        "\n",
        "layer = GATLayer(2, 2, num_heads=2)\n",
        "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
        "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
        "layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
        "\n",
        "with torch.no_grad():\n",
        "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
        "\n",
        "print(\"Adjacency matrix\", adj_matrix)\n",
        "print(\"Input features\", node_feats)\n",
        "print(\"Output features\", out_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EurweR8wxufm",
        "outputId": "fafd73fc-5b9d-4bb0-86ec-8aaa61463921"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention probs\n",
            " tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n",
            "          [0.1096, 0.1450, 0.2642, 0.4813],\n",
            "          [0.0000, 0.1858, 0.2885, 0.5257],\n",
            "          [0.0000, 0.2391, 0.2696, 0.4913]],\n",
            "\n",
            "         [[0.5100, 0.4900, 0.0000, 0.0000],\n",
            "          [0.2975, 0.2436, 0.2340, 0.2249],\n",
            "          [0.0000, 0.3838, 0.3142, 0.3019],\n",
            "          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n",
            "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.]]])\n",
            "Input features tensor([[[0., 1.],\n",
            "         [2., 3.],\n",
            "         [4., 5.],\n",
            "         [6., 7.]]])\n",
            "Output features tensor([[[1.2913, 1.9800],\n",
            "         [4.2344, 3.7725],\n",
            "         [4.6798, 4.8362],\n",
            "         [4.5043, 4.7351]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Torch Geometric"
      ],
      "metadata": {
        "id": "_VBk_SPm0frj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch geometric\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version.\n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details\n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-geometric\n",
        "    import torch_geometric\n",
        "    \n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data"
      ],
      "metadata": {
        "id": "WN049niex5fO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc77939-8847-4c57-dd46-2449304b50d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 15.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 26.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 26.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 28.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=ed58a714c01c2b13308cb130550235f719d3189d2494f5bfc0fe990fb2557333\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layers Dictionary"
      ],
      "metadata": {
        "id": "ZoWZXMDb0lL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_layer_by_name = {\n",
        "    \"GCN\": geom_nn.GCNConv,\n",
        "    \"GAT\": geom_nn.GATConv,\n",
        "    \"GraphConv\": geom_nn.GraphConv\n",
        "}"
      ],
      "metadata": {
        "id": "Hh0jd74VyASj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node Classification"
      ],
      "metadata": {
        "id": "_r4U7j23yNJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading Dataset"
      ],
      "metadata": {
        "id": "jqY5ThIC0s00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")\n",
        "cora_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo0xf-4OyJOS",
        "outputId": "33682f26-28ac-46fa-b727-6e2064d172da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP baseline Model"
      ],
      "metadata": {
        "id": "G_yGJXND1MB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            num_layers - Number of hidden layers\n",
        "            dp_rate - Dropout rate to apply throughout the network\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            layers += [\n",
        "                nn.Linear(in_channels, out_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dp_rate)\n",
        "            ]\n",
        "            in_channels = c_hidden\n",
        "        layers += [nn.Linear(in_channels, c_out)]\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "        \"\"\"\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "MPJaEpCrylle"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN Model"
      ],
      "metadata": {
        "id": "2Gh68QxKym_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            num_layers - Number of \"hidden\" graph layers\n",
        "            layer_name - String of the graph layer to use\n",
        "            dp_rate - Dropout rate to apply throughout the network\n",
        "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        gnn_layer = gnn_layer_by_name[layer_name]\n",
        "\n",
        "        layers = []\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            layers += [\n",
        "                gnn_layer(in_channels=in_channels,\n",
        "                          out_channels=out_channels,\n",
        "                          **kwargs),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dp_rate)\n",
        "            ]\n",
        "            in_channels = c_hidden\n",
        "        layers += [gnn_layer(in_channels=in_channels,\n",
        "                             out_channels=c_out,\n",
        "                             **kwargs)]\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "        \"\"\"\n",
        "        for l in self.layers:\n",
        "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
        "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
        "            # we can simply check the class type.\n",
        "            if isinstance(l, geom_nn.MessagePassing):\n",
        "                x = l(x, edge_index)\n",
        "            else:\n",
        "                x = l(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "SI7CJYZLyfQf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NodeLevelGNN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        if model_name == \"MLP\":\n",
        "            self.model = MLPModel(**model_kwargs)\n",
        "        else:\n",
        "            self.model = GNNModel(**model_kwargs)\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.model(x, edge_index)\n",
        "\n",
        "        # Only calculate the loss on the nodes corresponding to the mask\n",
        "        if mode == \"train\":\n",
        "            mask = data.train_mask\n",
        "        elif mode == \"val\":\n",
        "            mask = data.val_mask\n",
        "        elif mode == \"test\":\n",
        "            mask = data.test_mask\n",
        "        else:\n",
        "            assert False, f\"Unknown forward mode: {mode}\"\n",
        "\n",
        "        loss = self.loss_module(x[mask], data.y[mask])\n",
        "        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum()\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # We use SGD here, but Adam works as well\n",
        "        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"val\")\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"test\")\n",
        "        self.log('test_acc', acc)"
      ],
      "metadata": {
        "id": "gJgkH2coytm-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
        "    pl.seed_everything(42)\n",
        "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n",
        "\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
        "                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n",
        "                         max_epochs=200,\n",
        "                         progress_bar_refresh_rate=0) # 0 because epoch size is 1\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"NodeLevel{model_name}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        print(pretrained_filename)\n",
        "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything()\n",
        "        model = NodeLevelGNN(model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs)\n",
        "        trainer.fit(model, node_data_loader, node_data_loader)\n",
        "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "\n",
        "    # Test best model on the test set\n",
        "    test_result = trainer.test(model, node_data_loader, verbose=False)\n",
        "    batch = next(iter(node_data_loader))\n",
        "    batch = batch.to(model.device)\n",
        "    _, train_acc = model.forward(batch, mode=\"train\")\n",
        "    _, val_acc = model.forward(batch, mode=\"val\")\n",
        "    result = {\"train\": train_acc,\n",
        "              \"val\": val_acc,\n",
        "              \"test\": test_result[0]['test_acc']}\n",
        "    return model, result"
      ],
      "metadata": {
        "id": "AKtFpnfZyzT3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results(result_dict):\n",
        "    if \"train\" in result_dict:\n",
        "        print(f\"Train accuracy: {(100.0*result_dict['train']):4.2f}%\")\n",
        "    if \"val\" in result_dict:\n",
        "        print(f\"Val accuracy:   {(100.0*result_dict['val']):4.2f}%\")\n",
        "    print(f\"Test accuracy:  {(100.0*result_dict['test']):4.2f}%\")"
      ],
      "metadata": {
        "id": "23XSNgmay40b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP Results"
      ],
      "metadata": {
        "id": "Yyg9sEsM1jV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_mlp_model, node_mlp_result = train_node_classifier(model_name=\"MLP\",\n",
        "                                                        dataset=cora_dataset,\n",
        "                                                        c_hidden=16,\n",
        "                                                        num_layers=2,\n",
        "                                                        dp_rate=0.1)\n",
        "\n",
        "print_results(node_mlp_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDi3p8xSy7jO",
        "outputId": "be4445df-4804-4cbe-b09e-23a40e67df58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/saved_models/NodeLevelMLP/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n",
            "/content//saved_models/NodeLevelMLP.ckpt\n",
            "Train accuracy: 97.14%\n",
            "Val accuracy:   54.60%\n",
            "Test accuracy:  60.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCN Results"
      ],
      "metadata": {
        "id": "nA5Q81_V1pff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_gnn_model, node_gnn_result = train_node_classifier(model_name=\"GNN\",\n",
        "                                                        layer_name=\"GCN\",\n",
        "                                                        dataset=cora_dataset,\n",
        "                                                        c_hidden=16,\n",
        "                                                        num_layers=2,\n",
        "                                                        dp_rate=0.1)\n",
        "print_results(node_gnn_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbo_lDT6y--q",
        "outputId": "e4a8131e-a04d-4079-8d6b-6f7943882102"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/saved_models/NodeLevelGNN/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n",
            "/content//saved_models/NodeLevelGNN.ckpt\n",
            "Train accuracy: 100.00%\n",
            "Val accuracy:   78.60%\n",
            "Test accuracy:  82.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT Results"
      ],
      "metadata": {
        "id": "wwf59Ily1wmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_gnn_model, node_gnn_result = train_node_classifier(model_name=\"GNN\",\n",
        "                                                        layer_name=\"GCN\",\n",
        "                                                        dataset=cora_dataset,\n",
        "                                                        c_hidden=16,\n",
        "                                                        num_layers=2,\n",
        "                                                        dp_rate=0.1)\n",
        "print_results(node_gnn_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O7EHsk5zDdc",
        "outputId": "1bbf58e9-1a45-46c5-8cd6-02023e81bc17"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n",
            "/content//saved_models/NodeLevelGNN.ckpt\n",
            "Train accuracy: 100.00%\n",
            "Val accuracy:   78.60%\n",
            "Test accuracy:  82.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edge level Tasks - Link prediction"
      ],
      "metadata": {
        "id": "prxtbe6VI2VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
        "                      add_negative_train_samples=False),\n",
        "])\n",
        "\n",
        "\n",
        "dataset = Planetoid(root='.', name='Cora',transform=transform)\n",
        "\n",
        "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
        "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
        "# each element representing the corresponding split.\n",
        "train_data, val_data, test_data = dataset[0]\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GATConv(hidden_channels, out_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
        "\n",
        "\n",
        "model = Net(dataset.num_features, 128, 64).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "\n",
        "    # We perform a new round of negative sampling for every training epoch:\n",
        "    neg_edge_index = negative_sampling(\n",
        "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
        "\n",
        "    edge_label_index = torch.cat(\n",
        "        [train_data.edge_label_index, neg_edge_index],\n",
        "        dim=-1,\n",
        "    )\n",
        "    edge_label = torch.cat([\n",
        "        train_data.edge_label,\n",
        "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "    ], dim=0)\n",
        "\n",
        "    out = model.decode(z, edge_label_index).view(-1)\n",
        "    loss = criterion(out, edge_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
        "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
        "\n",
        "\n",
        "best_val_auc = final_test_auc = 0\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    val_auc = test(val_data)\n",
        "    test_auc = test(test_data)\n",
        "    if val_auc > best_val_auc:\n",
        "        best_val = val_auc\n",
        "        final_test_auc = test_auc\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
        "          f'Test: {test_auc:.4f}')\n",
        "\n",
        "print(f'Final Test: {final_test_auc:.4f}')\n",
        "\n",
        "z = model.encode(test_data.x, test_data.edge_index)\n",
        "final_edge_index = model.decode_all(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IytlNxTC1zRq",
        "outputId": "329b86b6-b3ca-4849-c44b-69803e9d9505"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.6931, Val: 0.7936, Test: 0.7716\n",
            "Epoch: 002, Loss: 0.6923, Val: 0.7043, Test: 0.6952\n",
            "Epoch: 003, Loss: 0.6903, Val: 0.7337, Test: 0.7210\n",
            "Epoch: 004, Loss: 0.6858, Val: 0.7485, Test: 0.7296\n",
            "Epoch: 005, Loss: 0.6775, Val: 0.8353, Test: 0.8302\n",
            "Epoch: 006, Loss: 0.6631, Val: 0.8290, Test: 0.8214\n",
            "Epoch: 007, Loss: 0.6411, Val: 0.8414, Test: 0.8414\n",
            "Epoch: 008, Loss: 0.6099, Val: 0.8423, Test: 0.8523\n",
            "Epoch: 009, Loss: 0.5731, Val: 0.8360, Test: 0.8346\n",
            "Epoch: 010, Loss: 0.5481, Val: 0.8087, Test: 0.8359\n",
            "Epoch: 011, Loss: 0.5463, Val: 0.8379, Test: 0.8463\n",
            "Epoch: 012, Loss: 0.5280, Val: 0.8383, Test: 0.8393\n",
            "Epoch: 013, Loss: 0.5556, Val: 0.8388, Test: 0.8512\n",
            "Epoch: 014, Loss: 0.5422, Val: 0.8310, Test: 0.8492\n",
            "Epoch: 015, Loss: 0.5418, Val: 0.8480, Test: 0.8618\n",
            "Epoch: 016, Loss: 0.5177, Val: 0.8588, Test: 0.8669\n",
            "Epoch: 017, Loss: 0.5087, Val: 0.8637, Test: 0.8709\n",
            "Epoch: 018, Loss: 0.5072, Val: 0.8699, Test: 0.8808\n",
            "Epoch: 019, Loss: 0.4952, Val: 0.8677, Test: 0.8824\n",
            "Epoch: 020, Loss: 0.4933, Val: 0.8634, Test: 0.8788\n",
            "Epoch: 021, Loss: 0.4927, Val: 0.8656, Test: 0.8794\n",
            "Epoch: 022, Loss: 0.4960, Val: 0.8663, Test: 0.8781\n",
            "Epoch: 023, Loss: 0.5029, Val: 0.8627, Test: 0.8757\n",
            "Epoch: 024, Loss: 0.4972, Val: 0.8599, Test: 0.8748\n",
            "Epoch: 025, Loss: 0.4982, Val: 0.8593, Test: 0.8748\n",
            "Epoch: 026, Loss: 0.4928, Val: 0.8631, Test: 0.8776\n",
            "Epoch: 027, Loss: 0.4929, Val: 0.8683, Test: 0.8815\n",
            "Epoch: 028, Loss: 0.4843, Val: 0.8728, Test: 0.8852\n",
            "Epoch: 029, Loss: 0.4774, Val: 0.8748, Test: 0.8900\n",
            "Epoch: 030, Loss: 0.4851, Val: 0.8721, Test: 0.8897\n",
            "Epoch: 031, Loss: 0.4760, Val: 0.8747, Test: 0.8919\n",
            "Epoch: 032, Loss: 0.4784, Val: 0.8800, Test: 0.8946\n",
            "Epoch: 033, Loss: 0.4751, Val: 0.8808, Test: 0.8945\n",
            "Epoch: 034, Loss: 0.4742, Val: 0.8795, Test: 0.8953\n",
            "Epoch: 035, Loss: 0.4780, Val: 0.8776, Test: 0.8953\n",
            "Epoch: 036, Loss: 0.4757, Val: 0.8791, Test: 0.8957\n",
            "Epoch: 037, Loss: 0.4733, Val: 0.8832, Test: 0.8977\n",
            "Epoch: 038, Loss: 0.4712, Val: 0.8840, Test: 0.8989\n",
            "Epoch: 039, Loss: 0.4645, Val: 0.8813, Test: 0.8984\n",
            "Epoch: 040, Loss: 0.4666, Val: 0.8776, Test: 0.8964\n",
            "Epoch: 041, Loss: 0.4699, Val: 0.8775, Test: 0.8970\n",
            "Epoch: 042, Loss: 0.4631, Val: 0.8812, Test: 0.8992\n",
            "Epoch: 043, Loss: 0.4616, Val: 0.8837, Test: 0.9000\n",
            "Epoch: 044, Loss: 0.4680, Val: 0.8836, Test: 0.9001\n",
            "Epoch: 045, Loss: 0.4662, Val: 0.8813, Test: 0.8986\n",
            "Epoch: 046, Loss: 0.4647, Val: 0.8801, Test: 0.8981\n",
            "Epoch: 047, Loss: 0.4643, Val: 0.8838, Test: 0.9006\n",
            "Epoch: 048, Loss: 0.4610, Val: 0.8872, Test: 0.9019\n",
            "Epoch: 049, Loss: 0.4608, Val: 0.8879, Test: 0.9020\n",
            "Epoch: 050, Loss: 0.4573, Val: 0.8890, Test: 0.9026\n",
            "Epoch: 051, Loss: 0.4465, Val: 0.8907, Test: 0.9037\n",
            "Epoch: 052, Loss: 0.4569, Val: 0.8929, Test: 0.9041\n",
            "Epoch: 053, Loss: 0.4528, Val: 0.8949, Test: 0.9038\n",
            "Epoch: 054, Loss: 0.4519, Val: 0.8953, Test: 0.9036\n",
            "Epoch: 055, Loss: 0.4531, Val: 0.8957, Test: 0.9033\n",
            "Epoch: 056, Loss: 0.4536, Val: 0.8966, Test: 0.9036\n",
            "Epoch: 057, Loss: 0.4565, Val: 0.8981, Test: 0.9041\n",
            "Epoch: 058, Loss: 0.4509, Val: 0.8983, Test: 0.9041\n",
            "Epoch: 059, Loss: 0.4606, Val: 0.8984, Test: 0.9033\n",
            "Epoch: 060, Loss: 0.4592, Val: 0.8995, Test: 0.9027\n",
            "Epoch: 061, Loss: 0.4533, Val: 0.9005, Test: 0.9039\n",
            "Epoch: 062, Loss: 0.4537, Val: 0.9008, Test: 0.9050\n",
            "Epoch: 063, Loss: 0.4515, Val: 0.9005, Test: 0.9053\n",
            "Epoch: 064, Loss: 0.4526, Val: 0.9009, Test: 0.9048\n",
            "Epoch: 065, Loss: 0.4475, Val: 0.9012, Test: 0.9052\n",
            "Epoch: 066, Loss: 0.4446, Val: 0.9007, Test: 0.9057\n",
            "Epoch: 067, Loss: 0.4485, Val: 0.8992, Test: 0.9053\n",
            "Epoch: 068, Loss: 0.4498, Val: 0.8988, Test: 0.9049\n",
            "Epoch: 069, Loss: 0.4512, Val: 0.8998, Test: 0.9053\n",
            "Epoch: 070, Loss: 0.4513, Val: 0.9004, Test: 0.9058\n",
            "Epoch: 071, Loss: 0.4532, Val: 0.8996, Test: 0.9058\n",
            "Epoch: 072, Loss: 0.4456, Val: 0.8986, Test: 0.9058\n",
            "Epoch: 073, Loss: 0.4441, Val: 0.8979, Test: 0.9055\n",
            "Epoch: 074, Loss: 0.4512, Val: 0.8973, Test: 0.9054\n",
            "Epoch: 075, Loss: 0.4416, Val: 0.8972, Test: 0.9054\n",
            "Epoch: 076, Loss: 0.4511, Val: 0.8976, Test: 0.9058\n",
            "Epoch: 077, Loss: 0.4420, Val: 0.8989, Test: 0.9074\n",
            "Epoch: 078, Loss: 0.4464, Val: 0.8992, Test: 0.9079\n",
            "Epoch: 079, Loss: 0.4427, Val: 0.8977, Test: 0.9075\n",
            "Epoch: 080, Loss: 0.4440, Val: 0.8960, Test: 0.9068\n",
            "Epoch: 081, Loss: 0.4526, Val: 0.8959, Test: 0.9074\n",
            "Epoch: 082, Loss: 0.4417, Val: 0.8973, Test: 0.9087\n",
            "Epoch: 083, Loss: 0.4512, Val: 0.8980, Test: 0.9094\n",
            "Epoch: 084, Loss: 0.4432, Val: 0.8962, Test: 0.9088\n",
            "Epoch: 085, Loss: 0.4455, Val: 0.8948, Test: 0.9081\n",
            "Epoch: 086, Loss: 0.4426, Val: 0.8956, Test: 0.9086\n",
            "Epoch: 087, Loss: 0.4461, Val: 0.8958, Test: 0.9093\n",
            "Epoch: 088, Loss: 0.4425, Val: 0.8955, Test: 0.9100\n",
            "Epoch: 089, Loss: 0.4415, Val: 0.8951, Test: 0.9100\n",
            "Epoch: 090, Loss: 0.4414, Val: 0.8936, Test: 0.9088\n",
            "Epoch: 091, Loss: 0.4356, Val: 0.8939, Test: 0.9084\n",
            "Epoch: 092, Loss: 0.4499, Val: 0.8938, Test: 0.9096\n",
            "Epoch: 093, Loss: 0.4425, Val: 0.8933, Test: 0.9102\n",
            "Epoch: 094, Loss: 0.4513, Val: 0.8927, Test: 0.9104\n",
            "Epoch: 095, Loss: 0.4435, Val: 0.8920, Test: 0.9091\n",
            "Epoch: 096, Loss: 0.4349, Val: 0.8921, Test: 0.9095\n",
            "Epoch: 097, Loss: 0.4394, Val: 0.8921, Test: 0.9100\n",
            "Epoch: 098, Loss: 0.4381, Val: 0.8901, Test: 0.9102\n",
            "Epoch: 099, Loss: 0.4340, Val: 0.8873, Test: 0.9096\n",
            "Epoch: 100, Loss: 0.4433, Val: 0.8884, Test: 0.9100\n",
            "Final Test: 0.9100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Level Tasks - Graph Classification"
      ],
      "metadata": {
        "id": "L53w5yX4JA3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eeu1HJrOJEWS",
        "outputId": "5d48cdb4-983b-4d1c-c9ce-840027a31bd8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Extracting /content/data/MUTAG/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistics for dataset"
      ],
      "metadata": {
        "id": "DtKWk8YoJIHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data object:\", tu_dataset.data)\n",
        "print(\"Length:\", len(tu_dataset))\n",
        "print(f\"Average label: {tu_dataset.data.y.float().mean().item():4.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrajuMSNJHj-",
        "outputId": "2b38e82f-e404-4bcd-92e0-d745fb0904c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data object: Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
            "Length: 188\n",
            "Average label: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "tu_dataset.shuffle()\n",
        "train_dataset = tu_dataset[:150]\n",
        "test_dataset = tu_dataset[150:]"
      ],
      "metadata": {
        "id": "6oRxo-8nJJ_o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=64) \n",
        "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "-4MFjv5tJLXV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(graph_test_loader))\n",
        "print(\"Batch:\", batch)\n",
        "print(\"Labels:\", batch.y[:10])\n",
        "print(\"Batch indices:\", batch.batch[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3hqNuoWJNfm",
        "outputId": "2f89fefc-bd50-4815-d484-ce66675b1a70"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: DataBatch(edge_index=[2, 1512], x=[687, 7], edge_attr=[1512, 4], y=[38], batch=[687], ptr=[39])\n",
            "Labels: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GNN Model"
      ],
      "metadata": {
        "id": "f4ETreiEJUsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphGNNModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of output features (usually number of classes)\n",
        "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
        "            kwargs - Additional arguments for the GNNModel object\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.GNN = GNNModel(c_in=c_in, \n",
        "                            c_hidden=c_hidden, \n",
        "                            c_out=c_hidden, # Not our prediction output yet!\n",
        "                            **kwargs)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dp_rate_linear),\n",
        "            nn.Linear(c_hidden, c_out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, batch_idx):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "            batch_idx - Index of batch element for each node\n",
        "        \"\"\"\n",
        "        x = self.GNN(x, edge_index)\n",
        "        x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7Fk5yHw3JOt_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch lightening module to handle training"
      ],
      "metadata": {
        "id": "f5U3WEkPJYe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphLevelGNN(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        self.model = GraphGNNModel(**model_kwargs)\n",
        "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
        "        x = self.model(x, edge_index, batch_idx)\n",
        "        x = x.squeeze(dim=-1)\n",
        "        \n",
        "        if self.hparams.c_out == 1:\n",
        "            preds = (x > 0).float()\n",
        "            data.y = data.y.float()\n",
        "        else:\n",
        "            preds = x.argmax(dim=-1)\n",
        "        loss = self.loss_module(x, data.y)\n",
        "        acc = (preds == data.y).sum().float() / preds.shape[0]\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) # High lr because of small dataset and small model\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"val\")\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"test\")\n",
        "        self.log('test_acc', acc)"
      ],
      "metadata": {
        "id": "Yk-qL-zpJXCj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "owcox6SFJckc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_graph_classifier(model_name, **model_kwargs):\n",
        "    pl.seed_everything(42)\n",
        "    \n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
        "                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n",
        "                         max_epochs=500,\n",
        "                         progress_bar_refresh_rate=0)\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"GraphLevel{model_name}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything(42)\n",
        "        model = GraphLevelGNN(c_in=tu_dataset.num_node_features, \n",
        "                              c_out=1 if tu_dataset.num_classes==2 else tu_dataset.num_classes, \n",
        "                              **model_kwargs)\n",
        "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
        "        model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "    # Test best model on validation and test set\n",
        "    train_result = trainer.test(model, graph_train_loader, verbose=False)\n",
        "    test_result = trainer.test(model, graph_test_loader, verbose=False)\n",
        "    result = {\"test\": test_result[0]['test_acc'], \"train\": train_result[0]['test_acc']} \n",
        "    return model, result"
      ],
      "metadata": {
        "id": "ICv0ESJ_JbD5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform Training and Testing"
      ],
      "metadata": {
        "id": "xwhpHLr_Jg7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, result = train_graph_classifier(model_name=\"GraphConv\", \n",
        "                                       c_hidden=256, \n",
        "                                       layer_name=\"GraphConv\", \n",
        "                                       num_layers=3, \n",
        "                                       dp_rate_linear=0.5,\n",
        "                                       dp_rate=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLl4XSH1Jfne",
        "outputId": "b99438a4-455f-48ba-d8b2-db5bc0b3b759"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/saved_models/GraphLevelGraphConv/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train performance: {100.0*result['train']:4.2f}%\")\n",
        "print(f\"Test performance:  {100.0*result['test']:4.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmXBX0TJJjYC",
        "outputId": "a730030e-0a19-4fdc-9a3a-738a76d695c8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train performance: 93.28%\n",
            "Test performance:  92.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bKS9wVwWJk8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}